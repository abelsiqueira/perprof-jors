\subsection*{Introduction}

    The Performance Profile of a solver is the cumulative distribution
    function of a performance metric, e.g., CPU time, number of functions
    evaluations, number of iterations, or others, that we will call \emph{cost}.

    It was first described by \textcite{Dolan:2002du} and is presented as a 
    graphic that shows the relative performance profile of different solvers, 
    according to a chosen metric, for a given set of problem instances.

    Given a set $\Pset$ of problems and a set $\Sset$ of solvers, for each 
    problem $p \in \Pset$ and solver $s \in \Sset$, we define $t_{ps}$ as the  
    cost required to solve problem $p$ by solver $s$ and
    \begin{align*}
      r_{ps} = \frac{t_{ps}}{\min\{t_{ps}: s \in \Sset\}}
    \end{align*}
    as the performance ratio of solver $s$ for the problem $p$ when compared
    with the best performance by any solver on this problem.

    \citeauthor{Dolan:2002du} define the probability of a solver $s \in \Sset$ to
    solve one problem within a factor $\tau \in \mathds{R}$ of the best
    performance ratio as the function
    \begin{align*}
      \rho_s(\tau) = \frac{| \{p \in \Pset: r_{ps} \leq \tau\} |}{| \Pset |}
    \end{align*}
    For a given $\tau$, the best solver is the one with the highest value for
    $\rho_s(\tau)$.

\subsection*{Motivation}

    To facilitate the reproduction of data set analysis, such as the
    benchmarking of solvers analysis provided by \citeauthor{Dolan:2002du}'s
    performance profile, it is important to have an open source tool that handle
    the production of plots.

    Performance profile has been, over the years, the most used benchmark
    comparison tool used in optimization. Nevertheless, the production of such
    analysis is sometimes a task that can lead a researcher to waste a lot of
    time and effort that should have been spent in developing the solver itself,
    and not in creating the comparison plots. The main goal of our work was to
    create  a straightforward  tool that would allow one to create performance
    profile pictures in a fast and easy manner.

    Moreover,  we wanted to allow \LaTeX\ users, a group in which almost all
    optimization community is included,  to   generate performance profile plots
    within \LaTeX\ environment, and thus to get a better typographic result other
    than simple including raster  images.

    With these two main goals in mind, we developed and implemented perprof-py
    in Python 3 with internationalization features and direct \LaTeX\ integration.

\subsection*{Implementation and architecture}

    The software was implemented as a Python 3 package
    and organized
    to allow addition of new backends --  see Figure~\ref{fig:uml}.
    Users have a command line interface to use out of the box,
    however one can also use the package in their own software.

    \begin{figure}[!htb]
      \centering
      \includegraphics[width=0.45\textwidth]{uml/uml.pdf}
      \caption{UML of perprof}
      \label{fig:uml}
    \end{figure}

    The implementation is very straightforward. The algorithm:
    \begin{enumerate}
      \item parses the options passed as arguments, creating a
        structure with all the information;
      \item parses and process the input files, using the definition
        of the performance function to create the data to be plotted;
      \item uses the chosen backend to plot the data.
    \end{enumerate}

\subsection*{Input}

    For each solver to be compared in the benchmark, one must write a file in the following manner:

    \begin{verbatim}
---
YAML information
---
Problem01 exit01 time01
Problem02 exit02 time02
    \end{verbatim}

    In the YAML information one can set the name of the solver and some
    flags for perprof-py.
    Each line beyond that has 3 columns. The columns meaning, in order, are:
    \begin{itemize}
      \item The name of the problem;
      \item Exit flag;
      \item Cost measure -- for instance, elapsed time.
    \end{itemize}

\subsection*{Parsing process and output}

    To use perprof-py, the user needs to issue a command of the type
\begin{verbatim}
$ perprof OPTIONS BACKEND FILES
\end{verbatim}
    where
    \begin{itemize}
      \item FILES are the input files described in the previous section. At
        least two files input are required;
      \item BACKEND is one of the options \verb+--tikz+, \verb+--mp+,
        \verb+--bokeh+ or
        \verb+--raw+, which represents whether the user wants to use
        Tikz/PGFPLOTS, MatplotLib, Bokeh, or simply printing the performance
        ratios, respectively;
      \item OPTIONS are varied arguments that can be passed to perprof-py to
        customize the graphics or modify the performance functions. Some
        noteworthy options are
        \begin{itemize}
          \item \verb+--semilog+: the natural logarithmic scale is used on the abscissa axis;
          \item \verb+--success STR+: \verb+STR+ is a comma separated string
            of keys that was considered  \emph{success} by the solver;
          \item \verb+--black-and-white+: perprof-py creates the plots using only
            line styles and it colors them in black;
          \item \verb+--subset FILE+: perprof-py considers only the subset problems listed in \verb+FILE+, while creating the performance functions.
        \end{itemize}
    \end{itemize}
    In order to demonstrate such OPTIONS, Figures \ref{fig:example1}-\ref{fig:example4} show some examples of  performance profile graphics. 
    \begin{figure}[!ht]
      \centering
      \includegraphics[width=0.4\textwidth]{plots/abc.pdf}
      \caption{Example of performance profile with default options.}
      \label{fig:example1}
    \end{figure}
    \begin{figure}[!ht]
      \centering
      \includegraphics[width=0.4\textwidth]{plots/abc-semilog.pdf}
      \caption{Example of performance profile with semilog option.}
      \label{fig:example2}
    \end{figure}
    \begin{figure}[!ht]
      \centering
      \includegraphics[width=0.4\textwidth]{plots/abc-semilog-bw.pdf}
      \caption{Example of performance profile with semilog and black and white
        options.}
      \label{fig:example3}
    \end{figure}
    \begin{figure}[!ht]
      \centering
      \includegraphics[width=0.4\textwidth]{plots/abc-semilog-hs.pdf}
      \caption{Example of performance profile with semilog and subset options.}
      \label{fig:example4}
    \end{figure}

\subsection*{Quality control}

    The code is tested using unit tests that verify if wrong input information
    is captured. These tests are run automatically on Travis CI
    \cite{url:travis}, for Python 3.3 and 3.4.
    Functional tests related to the graphics must be done manually.
    These tests use artifial solver information accessible using \verb+--demo+
    as argument in the perprof-py call. The user can run a script that makes
    several of these graphics in various formats by entering the folder
    \verb+perprof/examples+ relative to the package folder, and running
\begin{verbatim}
./make-examples.sh
\end{verbatim}
    The folder \verb+plots+ will contain the outputs in formats PNG, PDF and HTML.
