\documentclass[10pt,a4paper]{article}
\usepackage[utf8]{inputenx}
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage[english]{babel}
\usepackage[top=3cm,bottom=3cm,outer=3.2cm,inner=3.2cm]{geometry}
\usepackage[backend=biber,sortcites=true,doi=false,url=false,firstinits=true,hyperref,maxbibnames=9,maxcitenames=3,sorting=nyt]{biblatex}

\addbibresource{refs.bib}
\usepackage{csquotes}
\usepackage{url}
\usepackage{hyperref}
\usepackage{mathtools}
\usepackage{dsfont}       %Stroke Fonts for Number Sets

\def\Pset{\mathcal{P}}
\def\Sset{\mathcal{S}}

\begin{document}
\title{Perprof-py: a {P}ython package for performance profile}
\author{ Abel Soares Siqueira\thanks{IMECC/Unicamp}  \and Raniere Gaia Costa da
  Silva\thanks{IMECC/Unicamp.} \and Luiz-Rafael Santos\thanks{IMECC/Unicamp}}
\date{Technical Report \\ Operational Research and Optimization Laboratory
  (LPOO) \\ IMECC/Unicamp \\ Campinas, Brazil \\ \today}
\maketitle

\begin{abstract}
    A very important part of research in optimization field is to benchmark
    optimization packages, not only because it is one of the ways to compare
    solvers, but also because it allows one to uncover deficiencies that could
    be overlooked while developing a new solver. During benchmarking, one can
    obtain a large amount of  informations, like CPU time, number of functions
    evaluations, number of iterations and much more. These informations, if
    presented as tables, can be difficult to be analyzed, due, for instance, to
    large amount of data.  Therefore, researchers started testing and developing
    tools to better process and understand optimization benchmark data. One of
    the most widespread tools is \emph{Performance Profile} graphics proposed by
    \textcite{Dolan:2002du}. In this context, we implemented a free software
    that makes Performance Profile graphics using data provided by user in a
    friendly manner. This software produces graphics in PDF using \LaTeX with
    PGF/TikZ~\cite{TikZ} and \texttt{pgfplots}~\cite{pgfplots} packages, and in
    PNG using \texttt{matplotlib}~\cite{Hunter:2007} and it can also be easily
    extended to be used with other plots libraries. The software is implemented
    in Python3 with support for internationalization and is under GPL (General
    Public License) Version 3.
    %and is available on \url{https://github.com/lpoo/perprof-py}.

    \textbf{Keywords:} Software benchmarking.  Optimization. Performance profile. Python 3.
\end{abstract}

\section*{(1) Overview}

\subsection*{Introduction}

    The Performance Profile of a solver is the cumulative distribution
    function of a performance metric, e.g., CPU time, number of functions
    evaluations, number of iterations, or others, that we will call \emph{cost}.

    Given a set $\Pset$ of problems and a set $\Sset$ of solvers, for each problem $p
    \in \Pset$ and solver $s \in \Sset$, we define $t_{ps}$ as the cost
    required to solve problem $p$ by solver $s$ and
    \begin{align*}
      r_{ps} = \frac{t_{ps}}{\min\{t_{ps}: s \in \Sset\}}
    \end{align*}
    as the performance ratio of solver $s$ for the problem $p$ when compared
    with the best performance by any solver on this problem.

    \textcite{Dolan:2002du} defines the probability for solver $s \in \Sset$ to
    solve one problem within a factor $\tau \in \mathds{R}$ of the best
    performance ratio as the function
    \begin{align*}
      \rho_s(\tau) = \frac{| \{p \in \Pset: r_{ps} \leq \tau\} |}{| \Pset |}
    \end{align*}
    For a given $\tau$, the best solver is the one with the highest value for
    $\rho_s(\tau)$.

\subsection*{Motivation}

    To facilitate the reproduction of data set analysis, such as the
    benchmarking of solvers analysis provided by \citeauthor{Dolan:2002du}'s
    performance profile, it is important to have an open source tool that handle
    the production of plots.

    Performance profile has been, over the years, the most used benchmark
    comparison tool used in optimization. Nevertheless, the production of such
    analysis is sometimes a task that can lead a researcher to waste a lot of
    time and effort that should have been spent in developing the solver itself,
    and not in creating the comparison plots. The main goal of our work was to
    create  a straightforward  tool that would allow one to create performance
    profile pictures in a fast and easy manner.

    Moreover,  we wanted to allow LaTeX users, a group in which almost all
    optimization community is included,  to   generate performance profile plots
    within LaTeX environment, and thus to get a better typographic result other
    than simple including raster  images.

    With these two main goals in mind, we developed and implemented perprof-py
    in python3 with internationalization features and direct LaTeX integration.

\subsection*{Implementation and architecture}

    How the software was implemented, with details of the architecture where
    relevant. Use of relevant UML diagrams may be appropriate. Please also
    describe any variants and associated implementation differences.

\subsection*{Input}

    Each solver to be used in the benchmark must have a file like:

    \begin{verbatim}
---
YAML information
---
Problem01 exit01 time01
Problem02 exit02 time02
    \end{verbatim}

    In the YAML information you can set the name of the solver, and some
    flags for perprof-py.
    Each line beyond that has 3 columns that mean, in order:
    \begin{itemize}
      \item The name of the problem;
      \item Exit flag;
      \item Elapsed time.
    \end{itemize}

\subsection*{Parsing process and output}

\subsection*{Quality control}

    Detail the level of testing that has been carried out on the code (e.g.
    unit, functional, load etc.), and in which environments.

\section*{(2) Availability}

\subsection*{Operating system}

    Perprof-py is developed and actively tested on Unix plaftorms, however, it
    is also possible to run it on Windows, removing some features.

\subsection*{Programming language}

    The project was made entirely with python3.

\subsection*{Additional system requirements}

    No additional hardware requirement are necessary.

\subsection*{Dependencies}

    Perprof-py depends on the Python packages matplotlib-1.3.1, nose-1.3.0,
    numpy-1.8.0, pyparsing-2.0.1, python-dateutil-2.2, six-1.4.1, tornado-3.1.1
    and pyyaml. Additionally, if the user wants the a PDF from the LaTeX
    version, it also requires pdflatex.

\subsection*{List of contributors}

    Please list anyone who helped to create the software (who may also not be an
    author of this paper), including their roles and affiliations.

\subsection*{Software location:}

    Archive

    \paragraph{Name:} perprof-py

    \paragraph{Identifier:} \url{https://github.com/lpoo/perprof-py}

    \paragraph{Licence:} GPL (General Public License) Version 3

    \paragraph{Date published:} 24/03/14

    \paragraph{Publisher:} Name of the person who deposited the software

    \paragraph{Date published:} 24/03/14

    \paragraph{Code repository}

    \paragraph{Name:} GitHub

    \paragraph{Identifier:} \url{https://github.com/lpoo/perprof-py}

    \paragraph{Licence:} GPL (General Public License) Version 3

    \paragraph{Date published:} 24/03/14

    Language

    Language of repository, software and supporting files

\section*{(3) Reuse potential}

\printbibliography
\end{document}
